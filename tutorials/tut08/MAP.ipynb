{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAP - Multi Agent Planning\n",
    "##### Aviv Cohen & Dan Navon\n",
    "\n",
    "## Introduction\n",
    "Multiagent planning is concerned with planning by (and for) multiple agents. It can involve agents planning for a common goal, an agent coordinating the plans (plan merging) or planning of others, or agents refining their own plans while negotiating over tasks or resources.\n",
    "\n",
    "## Motivation\n",
    "On 236609 - MULTI ROBOT SYSTEMS - Sarah's previous course, we faced the collaborative inspection problem where 2 agents needs to collaborate in order to count as many spheres as possible.\n",
    "\n",
    "<img src='img/inspection.jpg' width=500/>\n",
    "\n",
    "Our single agent solution implementation dependent on splitting the graph such that both agent will finish revealing the scene on the shortest possible time.\n",
    "Since we faced difficulties we implemented it naively were each robot goes to its closest area.\n",
    "\n",
    "<img src='img/Motivation.jpeg' width=500/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The problem\n",
    "\n",
    "State space - $\\mathcal{S} = S^0 \\times ... \\times S^k \\times ... \\times S^{k+i} \\times ... \\times S^{k+i+j} $ where $k$ is the number of taxis, $i$ the number of passengers and $j$ number of their destination. $S$ represents the map's dimensions.\n",
    "joint action space - $\\mathcal{A} = A^0 \\times ... \\times A^k $ taxis and $A$ represent the number of actions each taxi can perform.\n",
    "\n",
    "The joint graph will describe each possible expansion of $s \\in \\mathcal{S}$ using $a \\in \\mathcal{A}$ to $s' \\in \\mathcal{S}$\n",
    "\n",
    "### Current settings\n",
    "Taxis will work in a cooperative / collaborative settings with centralized control, fully observable and implicit communication\n",
    "In order to test our algorithms, whe chose a domain 4x4 map with 2 taxis and 2 passengers.\n",
    "$|\\mathcal{S}| = (4\\cdot 4)^{2+2+2} = 16^6 = 16,777,216$\n",
    "$|\\mathcal{A}| = 7^2 = 49$\n",
    "\n",
    "We can now understand why MAP is such a complex task, even for a relatively small size of domain our space-state action is huge.\n",
    "\n",
    "### Pruning\n",
    "\n",
    "In order to reduce the amount of nodes we'll explore, we tested whether the state will be changed after each joint action.\n",
    " If picking or dropoff won't change taxi's location we omit this action before its processed into successors data structure.\n",
    " The chosen domain is small and contain a few barriers at the middle, we see that we usually have around 12 different joint actions which greatly reduce the running time.\n",
    "\n",
    "### Makespan\n",
    "\n",
    "Makespan of a project is the length of time that elapses from the start of work to the end.\n",
    "In our scenario, makespan related to the longest path to be executed by one of the agents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Agent BFS\n",
    "In order to find a solution to the makespan problem, one can use BFS which guarantee to find a solution if it exists.\n",
    "The advantage of using BFS is its general purpose which can use to achieve different goals such as solution to the makespan issue or collaboration, but it comes with a price of expanding multiple nodes.\n",
    "\n",
    "We would like to start with performing uninformed search as a benchmark over the state-joint action graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# not needed with provided conda environment\n",
    "# !pip install git+https://github.com/sarah-keren/multi_taxi\n",
    "# !pip install git+https://github.com/sarah-keren/AI_agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment\n",
    "We'll test our MultiAgentPlanning algorithms over the taxi environment we've already seen with the use of best_first_search as the search backbone for A* and BFS.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from copy import deepcopy\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.csgraph import maximum_bipartite_matching\n",
    "\n",
    "from multi_taxi import MultiTaxiEnv\n",
    "from AI_agents.Search.best_first_search import breadth_first_search, a_star\n",
    "from MAP import MapProblem\n",
    "from copy import deepcopy\n",
    "import copy\n",
    "\n",
    "\n",
    "MAP2 = [\n",
    "    \"+-------+\",\n",
    "    \"| : |F: |\",\n",
    "    \"| : | : |\",\n",
    "    \"| : : : |\",\n",
    "    \"| | :G| |\",\n",
    "    \"+-------+\",\n",
    "]\n",
    "\n",
    "taxi_env = MultiTaxiEnv(num_taxis=2, num_passengers=2, domain_map=MAP2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to be compatible with both AI_agents library and the TaxiEnvironment we have to switch the state represntation between list of lists and tuple of tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def list_to_tuple(x):\n",
    "    lolol = deepcopy(x) # list of lists of lists\n",
    "    result = list()\n",
    "    while lolol:\n",
    "        lol = lolol.pop(0)\n",
    "        # single list\n",
    "        if type(lol[0]) is not list:\n",
    "            result.append(tuple(lol))\n",
    "\n",
    "        # list of lists\n",
    "        else:\n",
    "            local_res = list()\n",
    "            while lol:\n",
    "                l = lol.pop(0)\n",
    "                local_res.append(tuple(l))\n",
    "            result.append(tuple(local_res))\n",
    "\n",
    "    return tuple(result)\n",
    "\n",
    "\n",
    "def tuple_to_list(x):\n",
    "    totot = list(x)\n",
    "    result = list()\n",
    "    while totot:\n",
    "        tot = totot.pop(0)\n",
    "        if type(tot[0]) is not tuple:\n",
    "            result.append(list(tot))\n",
    "        else:\n",
    "            tot = list(tot)\n",
    "            local_res = list()\n",
    "            while tot:\n",
    "                t = tot.pop(0)\n",
    "                local_res.append(list(t))\n",
    "            result.append(list(local_res))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def run_plan(state, plan, problem):\n",
    "    new_state = deepcopy(state)\n",
    "    problem.env.reset()\n",
    "    problem.set_state(state)\n",
    "    problem.env.render()\n",
    "    for action in plan:\n",
    "        time.sleep(0.25)\n",
    "        new_state = problem.step(eval(action))\n",
    "        clear_output(wait=True)\n",
    "        problem.env.render()\n",
    "\n",
    "    return new_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing MapProblem class to describe our Multi Agent Planning problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "| : |F: |\n",
      "| : |\u001b[32m\u001b[31;1mD\u001b[0m\u001b[0m:\u001b[32m\u001b[33;1mD\u001b[0m\u001b[0m|\n",
      "| :\u001b[41m_\u001b[0m:\u001b[43m_\u001b[0m: |\n",
      "| |\u001b[33;1mP\u001b[0m:G|\u001b[31;1mP\u001b[0m|\n",
      "+-------+\n",
      "Taxi0-YELLOW: Fuel: inf, Location: (2,2), Collided: False\n",
      "Taxi1-RED: Fuel: inf, Location: (2,1), Collided: False\n",
      "Passenger1: Location: (3, 1), Destination: (1, 3)\n",
      "Passenger2: Location: (3, 3), Destination: (1, 2)\n",
      "Done: False, {'taxi_0': False, 'taxi_1': False, '__all__': False}\n",
      "Passengers Status's: [2, 2]\n"
     ]
    }
   ],
   "source": [
    "taxi_env.reset()\n",
    "initial_state=[[[2, 2], [2, 1]], [np.inf, np.inf], [[3, 1], [3, 3]], [[1, 3], [1, 2]], [2, 2]]\n",
    "# initial_state=deepcopy(taxi_env.state)\n",
    "map_problem = MapProblem(taxi_env, list_to_tuple(initial_state))\n",
    "map_problem.set_state(initial_state)\n",
    "taxi_env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executing BFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path length: 8\n",
      "explored_count: 600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plan = breadth_first_search(map_problem)\n",
    "[best_value, best_node, path, explored_count, ex_terminated] = plan\n",
    "print('path length:', len(path))\n",
    "print('explored_count:', explored_count)\n",
    "explored_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path length: 8\n",
      "explored count: 600\n"
     ]
    }
   ],
   "source": [
    "\n",
    "plan = breadth_first_search(map_problem)\n",
    "[best_value, best_node, path, explored_count, ex_terminated] = plan\n",
    "print('path length:', len(path))\n",
    "print('explored count:', explored_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "| : |F: |\n",
      "| : |\u001b[32m\u001b[41m_\u001b[0m\u001b[0m:\u001b[32m\u001b[43m_\u001b[0m\u001b[0m|\n",
      "| : : : |\n",
      "| | :G| |\n",
      "+-------+\n",
      "Taxi0-YELLOW: Fuel: inf, Location: (1,3), Collided: False\n",
      "Taxi1-RED: Fuel: inf, Location: (1,2), Collided: False\n",
      "Passenger1: Location: Arrived!, Destination: (1, 3)\n",
      "Passenger2: Location: Arrived!, Destination: (1, 2)\n",
      "Done: True, {'taxi_0': True, 'taxi_1': True, '__all__': True}\n",
      "Passengers Status's: [1, 1]\n",
      "path length: 8\n"
     ]
    }
   ],
   "source": [
    "s = deepcopy(initial_state)\n",
    "final_state = run_plan(s,path, map_problem)\n",
    "print('path length:', len(path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Too slow! can we do better?\n",
    "Yes! we've already seen it with at the single agent planning tutorial.\n",
    "This time, as in BFS, we expand each node according to its current distance from the base node with additional heuristic function which estimates the distance of the agents to their passengers and their destination.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def joint_simulation(state, h, print_simulation=False, domain_m=MAP2):\n",
    "    taxi_P = MultiTaxiEnv(num_taxis=len(state[0]), num_passengers=len(state[2]), domain_map=domain_m)\n",
    "    map_p = MapProblem(taxi_P, list_to_tuple(state))\n",
    "\n",
    "    [_, _, path, explored_count, _] = a_star(problem=map_p, heuristic_func=h)\n",
    "    if print_simulation:\n",
    "        run_plan(state,path,map_p)\n",
    "        print('explored_count:', explored_count)\n",
    "        print('path length:', len(path))\n",
    "    return path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### But what about the heuristic?\n",
    "Designing a good heuristic for a multi agents system isn't as trivial as one might think.\n",
    "We'll now present a simple approach for admissible heuristic - the shortest distance from one of thetaxis to\n",
    "we can try something like ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class MultiAgentsHeuristic:\n",
    "    def __init__(self, single_agent_heuristic, aggr_func ):\n",
    "        self.h = single_agent_heuristic\n",
    "        self.aggr_func = aggr_func\n",
    "\n",
    "    def __call__(self, node):\n",
    "        \"\"\"\n",
    "        return an object that presents the joint heuristic of this state, by using the heuristic of one agent and one task\n",
    "        \"\"\"\n",
    "        state = node.state.key\n",
    "        taxis_src = state[0]\n",
    "        passengers_src = state[2]\n",
    "        passengers_dst = state[3]\n",
    "        passengers_status = state[4]\n",
    "        values_mat = np.array([[self.h(taxi_id, taxi_src, passenger_src, passenger_dst, passenger_status)\n",
    "                                for passenger_src, passenger_dst, passenger_status\n",
    "                                in zip(passengers_src, passengers_dst, passengers_status)]\n",
    "                               for taxi_id, taxi_src in enumerate(taxis_src)])\n",
    "\n",
    "        # values, match = allocate_tasks(values_mat)\n",
    "        g_score = self.aggr_func(values_mat) + node.path_cost\n",
    "        return g_score\n",
    "\n",
    "def manhattan_distance(p, q):\n",
    "    return abs(p[0] - q[0]) + abs(p[1] - q[1])\n",
    "\n",
    "\n",
    "def manhattan_heuristic(taxi_id, taxi_src, passenger_src, passenger_dst, passenger_status):\n",
    "    \"\"\"\n",
    "    manhatten distance to from the taxi's source to the passenger's source, and from there to the passenger's destination\n",
    "    \"\"\"\n",
    "    is_waiting = passenger_status == 2\n",
    "    not_waiting = passenger_status != 2\n",
    "    has_arrived = passenger_status == 1\n",
    "    not_arrived = passenger_status != 1\n",
    "    in_taxi = taxi_id + 3 == passenger_status\n",
    "    return (manhattan_distance(taxi_src, passenger_src) + manhattan_distance(passenger_src, passenger_dst)) * is_waiting \\\n",
    "           + manhattan_distance(taxi_src, passenger_dst) * in_taxi + (2 - has_arrived - not_waiting)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def closest_passenger(values_mat):\n",
    "    return np.min(values_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "| : |F:\u001b[43m_\u001b[0m|\n",
      "| : |\u001b[32m\u001b[41m_\u001b[0m\u001b[0m:\u001b[32m \u001b[0m|\n",
      "| : : : |\n",
      "| | :G| |\n",
      "+-------+\n",
      "Taxi0-YELLOW: Fuel: inf, Location: (0,3), Collided: False\n",
      "Taxi1-RED: Fuel: inf, Location: (1,2), Collided: False\n",
      "Passenger1: Location: Arrived!, Destination: (1, 3)\n",
      "Passenger2: Location: Arrived!, Destination: (1, 2)\n",
      "Done: True, {'taxi_0': True, 'taxi_1': True, '__all__': True}\n",
      "Passengers Status's: [1, 1]\n",
      "explored_count: 1086\n",
      "path length: 12\n"
     ]
    }
   ],
   "source": [
    "# A* code with a simple reliable heuristic like the distance between the closest (taxi, passenger) pair\n",
    "\n",
    "s = deepcopy(initial_state)\n",
    "mah = MultiAgentsHeuristic(single_agent_heuristic=manhattan_heuristic,aggr_func=closest_passenger)\n",
    "path = joint_simulation(s,mah,print_simulation=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Better than before, but still slow. can we do better?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Decentralized Approach\n",
    "\n",
    "another approach to solve the planning problem is to use a decentralized method, and distribute the computations.\n",
    "for using that method, we have to reduce the generalization and to restrict our environment.\n",
    "\n",
    "our environment will contain n taxis and k passengers, such that n >= k, and each taxi could take one passenger at most.\n",
    "additionally, we will assume there is no interaction between the taxis.\n",
    "\n",
    "in this setting, our decentralized algorithm is:\n",
    "\n",
    "1. separate each pair of taxi and passenger to an isolated environment\n",
    "2. compute the cost of each pair individually (the number of actions the taxi has to do to take the passenger to his destination).\n",
    "3. allocate the tasks to the agents, in an optimal way.\n",
    "\n",
    "This approach can be distributed naturally, by separating the planning for each pair.\n",
    "\n",
    "what do we gain by using this approach except the distributed computations?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison Between Centralized And Decentralized Approaches Complexity\n",
    "\n",
    "let's say that the size of the optimal path is p, and the branching factor of each taxi is b.\n",
    "if we use the BFS algorithm, the complexity of the centralized approach is $O((b^2)^p) = O(b^{2p})$, while in the decentralized approach, the complexity of each taxi is $O(b^pnk)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task Allocation\n",
    "\n",
    "Now we will focus the third part of the decentralized method.\n",
    "Our task is to find an optimal matching between the taxis and the passengers.\n",
    "\n",
    "We can present out input as a bipartite fully connected weighted graph G = (U,V,W), where each node u in U represents a taxi, each node v in V represents a passenger, and each weight w(u,v), represents the cost of taking the passenger v to his destination, by using the taxi u."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img height=\"600\" src=\"img/bipartite graph.png\" width=\"300\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's formalize our goal.\n",
    "to do this, we will use the [matching](https://en.wikipedia.org/wiki/Matching_(graph_theory)) definition of the graph theory.\n",
    "one of our constraints is that we have to allocate a taxi for each passenger. that means, we have to find a maximal matching.\n",
    "given $M,M'$ maximal matches, let's define $M \\geq M'$, if the maximal edge of $M$ is greater than or equal to the maximal edge of $M'$.\n",
    "our goal is to optimize the makespan problem, that is we want to find a maximal matching $M$, such that for every maximal matching $M'$, $M \\leq M'$. from now on, we will call this matching the best makespan matching."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A trivial algorithm to find the best makespan matching\n",
    "we can do an exhaustive search over all the possible maximal matches to find the best one.\n",
    "the number of the possible maximal matches is ${n \\choose k}k!$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An iterative algorithm to find the best makespan matching\n",
    "\n",
    "let's suppose we know how to find a maximal matching in an unweighted bipartite graph (we will see how to that later).\n",
    "\n",
    "iterative algorithm:\n",
    "    1. ignore the weights of G, and find a maximal matching M.\n",
    "    2. remove the maximal edge from G.\n",
    "    3. ignore the weights of G, and find a maximal matching M'.\n",
    "    4. if size(M) = size(M'), then M <- M', and jump to 2. else, return M."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correctness of the algorithm\n",
    "if there is a better matching, it cannot contain the highest value edge, so we can remove it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An optimization of the algorithm\n",
    "instead of removing one edge each iteration, we can do a binary search- for each iteration, if the maximal matching is equals to the number of the passengers, then remove half of the edges with the highest value. otherwise, add half of the lowest value edges we removed at the last iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How can we find a maximal matching in a bipartite graph?\n",
    "reminder from algorithms course: there is a reduction from the maximal matching problem to the maximal flow problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img height=\"600\" src=\"img/flow network.png\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can solve this [maximal flow problem](https://en.wikipedia.org/wiki/Maximum_flow_problem) with the [Ford-Fulkerson algorithm](https://en.wikipedia.org/wiki/Ford%E2%80%93Fulkerson_algorithm) for example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The optimized iterative algorithm's complexity\n",
    "we have at most $log(|E|)$ iterations, and each iteration takes $O(|E||v|)$ (Ford-Fulkerson complexity). that means $O(|E||V|log(|V|))$.\n",
    "since the $|E| = nk$, and $|V| = n + k = O(n)$, the complexity is $O(kn^2log(n + k))$\n",
    "\n",
    "there is a slightly more efficient algorithm for finding a maximal matching in an unweighted bipartite graph, without using a flow network. it's slightly more complicated than Ford-Fulkerson method, so we decided to not present it.\n",
    "that algorithm is called [Hopcroft–Karp algorithm](https://en.wikipedia.org/wiki/Hopcroft%E2%80%93Karp_algorithm), and its complexity is $O(|E|\\sqrt|v|)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def allocate_tasks(values_mat, ret_array=False):\n",
    "    \"\"\"\n",
    "    param values_mat: a matrix A, s.t Aij is the value of agent i, when his task is j.\n",
    "    return the best makespan match v and its value. vi is the task of the agent i in the match.\n",
    "    \"\"\"\n",
    "\n",
    "    tasks_num = values_mat.shape[1]\n",
    "\n",
    "    sorted_rewards = sorted(values_mat.reshape(-1))\n",
    "\n",
    "    low = 0\n",
    "    high = len(sorted_rewards) - 1\n",
    "\n",
    "    match = [0]\n",
    "\n",
    "    while high > low:\n",
    "        mid = int((high + low) / 2)\n",
    "\n",
    "        reward_mat_copy = values_mat.copy()\n",
    "        reward_mat_copy[reward_mat_copy > sorted_rewards[mid]] = 0\n",
    "        match = maximum_bipartite_matching(csr_matrix(reward_mat_copy), perm_type='column')\n",
    "        if np.sum(match[match > 0]) < tasks_num:\n",
    "            high = mid\n",
    "        else:\n",
    "            low = mid + 1\n",
    "\n",
    "    weights = [values_mat[i][match[i]] for i in range(len(match)) if match[i] >= 0]\n",
    "    if ret_array:\n",
    "        match = [match[i[0]] for i in sorted(enumerate(weights), reverse=True, key=lambda x: x[1])]\n",
    "        return tuple(np.array(sorted(weights, reverse=True))), tuple(match)\n",
    "    if len(weights)==0:\n",
    "        ret = 0\n",
    "    else:\n",
    "        ret = np.max(weights)\n",
    "    return ret\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "maximum_bipartite_matching implements the Hopcroft–Karp algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running The Task Allocation\n",
    "now we will run the same simulation that we ran before, but in a distributed way as we saw, by using the Manhattan distance as a single agent heuristic.\n",
    "first, we will create the values matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def distributed_simulation(state, h, with_prints=False):\n",
    "    taxis_num = len(state[0])\n",
    "    passengers_num = len(state[2])\n",
    "    values_mat = np.zeros(taxis_num * passengers_num).reshape(taxis_num, passengers_num)\n",
    "    for i in range(len(state[0])):  # taxi_id\n",
    "        for j in range(len(state[2])):  # passenger_id\n",
    "            s = deepcopy([[state[0][i]], [np.inf], [state[2][j]], [state[3][j]], [state[4][j]]])\n",
    "            path = joint_simulation(s, h, print_simulation=with_prints)\n",
    "            values_mat[i][j] = len(path)\n",
    "    return values_mat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def manhattan_heuristic_single_agent(node):\n",
    "    state = node.state.key\n",
    "    taxi_src = state[0][0]\n",
    "    passenger_src = state[2][0]\n",
    "    passenger_dst = state[3][0]\n",
    "    passenger_status = state[4][0]\n",
    "    return manhattan_heuristic(0, taxi_src, passenger_src, passenger_dst, passenger_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "| : |F: |\n",
      "| : |\u001b[32m\u001b[31;1mD\u001b[0m\u001b[0m:\u001b[32m\u001b[33;1mD\u001b[0m\u001b[0m|\n",
      "| :\u001b[41m_\u001b[0m:\u001b[43m_\u001b[0m: |\n",
      "| |\u001b[33;1mP\u001b[0m:G|\u001b[31;1mP\u001b[0m|\n",
      "+-------+\n",
      "Taxi0-YELLOW: Fuel: inf, Location: (2,2), Collided: False\n",
      "Taxi1-RED: Fuel: inf, Location: (2,1), Collided: False\n",
      "Passenger1: Location: (3, 1), Destination: (1, 3)\n",
      "Passenger2: Location: (3, 3), Destination: (1, 2)\n",
      "Done: False, {'taxi_0': False, 'taxi_1': False, '__all__': False}\n",
      "Passengers Status's: [2, 2]\n"
     ]
    }
   ],
   "source": [
    "taxi_env.reset()\n",
    "map_problem.set_state(initial_state)\n",
    "taxi_env.render()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "| : |F: |\n",
      "| : |\u001b[32m\u001b[43m_\u001b[0m\u001b[0m: |\n",
      "| : : : |\n",
      "| | :G| |\n",
      "+-------+\n",
      "Taxi0-YELLOW: Fuel: inf, Location: (1,2), Collided: False\n",
      "Passenger1: Location: Arrived!, Destination: (1, 2)\n",
      "Done: True, {'taxi_0': True, '__all__': True}\n",
      "Passengers Status's: [1]\n",
      "explored_count: 9\n",
      "path length: 8\n",
      "[[8. 7.]\n",
      " [7. 8.]]\n"
     ]
    }
   ],
   "source": [
    "value_matrix = distributed_simulation(initial_state,manhattan_heuristic_single_agent,with_prints=True)\n",
    "print(value_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now, we will apply the allocate_tasks function with that values matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allocate_tasks(value_matrix,ret_array=True)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we got a vector V, such that Vi is the passenger that allocated to the taxi i."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Can we generalize our solution?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "what if the taxis can interact with each other?\n",
    "for example, lets say we don't allow the taxis to be in the same square at the same time.\n",
    "if they will plan the path separately, they couldn't predict if they will collide somewhere along the path.\n",
    "in this case, we won't get an optimal solution by using this method. so we don't have a choice, but to get back to the joint graph.\n",
    "but...\n",
    "\n",
    "##### we can use our matching algorithm to create a heuristic function for the multi-agent A*, based on a heuristic of every single agent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a multi-agent heuristic based on a given single agent heuristics\n",
    "let's say we have an admissible heuristic for each taxi and passenger pair.\n",
    "if we will create a matrix of values by using this heuristic values, instead of the distances values as we did before, we will get an admissible heuristic for the multi-agent system.\n",
    "proof: let $G$ be a bipartite graph with the real distances, and $G'$ the bipartite graph of the heuristic distances. for every matching $M(G)$, a maximal edge of $M(G)$ is bigger than a maximal edge of $M(G')$, because all the edges in $G'$, have lower value than the corresponding edges in $G$ (the heuristic is admissible). let $M'(G)$ be the best maximal matching of the real graph, and $M''(G')$ the best maximal matching of the heuristic graph. then, $M'(G) \\geq M'(G') \\geq M''(G')$, where the inequality refers to the maximal edge in the matching. the first inequality is derived from the previous claim, and the second inequality is derived from the definition of the best maximal matching.\n",
    "\n",
    "additionally, there is no other admissible heuristic for the multi-agent system that derived ONLY from these single agent's heuristics, which dominates the heuristic we defined.\n",
    "proof: lets say the given single agent's heuristic is the real distances between each pair of taxi and passenger.\n",
    "in that case, the defined multi-agent's heuristic is equals to the optimal solution of the makespan problem as we saw earlier. so every multi-agent's heuristic that dominates the defined one, is greater than the optimal solution. that is, its not admissible.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we will use this matching to create a heuristics for the multi-agent A*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "| : |F:\u001b[43m_\u001b[0m|\n",
      "| : |\u001b[32m\u001b[41m_\u001b[0m\u001b[0m:\u001b[32m \u001b[0m|\n",
      "| : : : |\n",
      "| | :G| |\n",
      "+-------+\n",
      "Taxi0-YELLOW: Fuel: inf, Location: (0,3), Collided: False\n",
      "Taxi1-RED: Fuel: inf, Location: (1,2), Collided: False\n",
      "Passenger1: Location: Arrived!, Destination: (1, 3)\n",
      "Passenger2: Location: Arrived!, Destination: (1, 2)\n",
      "Done: True, {'taxi_0': True, 'taxi_1': True, '__all__': True}\n",
      "Passengers Status's: [1, 1]\n",
      "explored_count: 1085\n",
      "path length: 12\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "mah = MultiAgentsHeuristic(single_agent_heuristic=manhattan_heuristic,aggr_func=allocate_tasks)\n",
    "\n",
    "path = joint_simulation(initial_state, mah, print_simulation=True)\n",
    "print(len(path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "we showed 2 different ways to solve the makespan problem. one of them was more general (the centralized one), while the other was more efficient (the decentralized one).\n",
    "we showed a matching algorithm that helped us to do a task allocation for the decentralized method, and helped us to create a good heuristic for the centralized method as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Further readings\n",
    "\n",
    "our tutorial focused on the makespan problem, but there are another common task allocation's goals.\n",
    "one of the most common goals is to optimize the average reward of the agents. that means, in our taxis problem, to optimize the average time of taking a passenger to his destination.\n",
    "for that problem, our \"best matching\" definition changes to the matching with the minimal average of the edges' weight.\n",
    "to find the best matching according to this definition, we have to use other matching algorithm.\n",
    "a well known algorithm that solves this problem is called  [Hungarian algorithm](https://en.wikipedia.org/wiki/Hungarian_algorithm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
